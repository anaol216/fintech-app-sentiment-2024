{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from google_play_scraper import reviews, Sort\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the output CSV path\n",
    "output_csv = 'data/raw_reviews.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank apps with their Google Play package names\n",
    "apps = {\n",
    "    \"CBE\": \"com.commercialbank.cbe\",     # Replace with correct package names\n",
    "    \"BOA\": \"com.bankofafrica.eba\",       # Replace with correct package names\n",
    "    \"Dashen\": \"com.dashenbank.mobile\"    # Replace with correct package names\n",
    "}\n",
    "\n",
    "all_reviews = []\n",
    "\n",
    "print(\"Starting to scrape reviews...\")\n",
    "\n",
    "for bank, package_name in apps.items():\n",
    "    print(f\"Scraping 400+ reviews for {bank}...\")\n",
    "    result, _ = reviews(\n",
    "        package_name,\n",
    "        lang='en',        # Use 'am' for Amharic if needed and supported\n",
    "        country='et',\n",
    "        sort=Sort.NEWEST,\n",
    "        count=400\n",
    "    )\n",
    "    \n",
    "    for r in result:\n",
    "        all_reviews.append({\n",
    "            \"review\": r['content'],\n",
    "            \"rating\": r['score'],\n",
    "            \"date\": r['at'],\n",
    "            \"bank\": bank,\n",
    "            \"source\": \"Google Play\"\n",
    "        })\n",
    "\n",
    "print(f\"Scraped {len(all_reviews)} reviews in total.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_reviews)\n",
    "\n",
    "# Drop duplicates based on the review text\n",
    "df.drop_duplicates(subset=['review'], inplace=True)\n",
    "\n",
    "# Drop rows with missing critical data\n",
    "df.dropna(subset=['review', 'rating', 'date'], inplace=True)\n",
    "\n",
    "# Normalize dates to YYYY-MM-DD format\n",
    "df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Data shape after cleaning: {df.shape}\")\n",
    "print(\"Sample data preview:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1234ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to CSV\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Cleaned data saved to '{output_csv}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary of Task 1 Data Collection & Preprocessing:\")\n",
    "print(f\"Total reviews collected (after cleaning): {len(df)}\")\n",
    "\n",
    "missing_data_percentage = df.isnull().mean() * 100\n",
    "print(\"\\nMissing Data Percentages:\")\n",
    "print(missing_data_percentage)\n",
    "\n",
    "print(\"\\nReviews per bank:\")\n",
    "print(df['bank'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load cleaned data\n",
    "df = pd.read_csv(\"data/cleaned/combined_cleaned_reviews.csv\")\n",
    "\n",
    "# Total reviews\n",
    "total_reviews = len(df)\n",
    "\n",
    "# Missing data %\n",
    "missing = df.isnull().mean() * 100\n",
    "\n",
    "print(f\"Total Reviews: {total_reviews}\")\n",
    "print(\"Missing Data Percentage per Column:\")\n",
    "print(missing)\n",
    "\n",
    "# Reviews per bank\n",
    "print(\"\\nReviews per Bank:\")\n",
    "print(df['bank'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62c902",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Use this cleaned dataset for sentiment and thematic analysis.\n",
    "- Implement further preprocessing if necessary.\n",
    "- Document the methodology in README.md.\n",
    "- Commit scripts and notebook with meaningful messages.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
